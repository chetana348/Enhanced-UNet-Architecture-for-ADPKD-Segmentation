{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6064f73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#import libraries and the functions we defined\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from Networks import models\n",
    "from keras_unet.losses import jaccard_distance\n",
    "from keras_unet.metrics import dice_coef\n",
    "#from PCAUNetPP.losses import Hausdorff_distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from Data_Gen_2D import DataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "802c37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all metrics to evaluate model\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "smooth = 1\n",
    "\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth=100): \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(K.abs(y_true_f * y_pred_f)) \n",
    "    sum_ = K.sum(K.abs(y_true_f) + K.abs(y_pred_f)) \n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth) \n",
    "    return (jac) * smooth \n",
    "\n",
    "def mean_length_error(y_true, y_pred):\n",
    "    y_true_f = K.sum(K.round(K.flatten(y_true)))\n",
    "    y_pred_f = K.sum(K.round(K.flatten(y_pred)))\n",
    "    delta = (y_pred_f - y_true_f)\n",
    "    return K.mean(K.tanh(delta))\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def np_dice_coef(y_true, y_pred):\n",
    "    tr = y_true.flatten()\n",
    "    pr = y_pred.flatten()\n",
    "    return (2. * np.sum(tr * pr) + smooth) / (np.sum(tr) + np.sum(pr) + smooth)\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + keras.backend.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = keras.backend.sum(keras.backend.round(keras.backend.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = keras.backend.sum(keras.backend.round(keras.backend.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + keras.backend.epsilon())\n",
    "\n",
    "def roc(y_true, y_pred):\n",
    "    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "    return 1 - (true_positives / (possible_positives + keras.backend.epsilon()))\n",
    "\n",
    "def IOU(y_true, y_pred):\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    union = np.logical_or(y_true, y_pred)\n",
    "    return np.sum(intersection) / np.sum(union)\n",
    "\n",
    "def HD(y_true, y_pred):\n",
    "    sum_sq = np.sum(np.square(y_true - y_pred))\n",
    "    return np.sqrt(sum_sq)\n",
    "\n",
    "\n",
    "def HD1(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    msd = K.mean(K.square(y_true_f - y_pred_f))\n",
    "    return msd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_set(data_path, phrase):\n",
    "    set_of = [f for f in os.listdir(data_path) if phrase in f]\n",
    "    return np.array(set_of)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0158d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_predictions = r'D:\\Results_CK\\Compression\\Numpy\\PCA\\Kidneys\\npy'\n",
    "filepath_predictions = r'D:\\Results_CK\\sUNet++\\Cyst\\npy'\n",
    "filepath_tensors = r'D:\\Results_CK\\sUNet++\\Cyst\\t'\n",
    "filepath_data = r\"D:\\Data_128\\data\\\\\"\n",
    "\n",
    "images = gather_set(filepath_predictions, 'P')\n",
    "model_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb1b4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = list(set([os.path.basename(image)[:14] for image in images]))\n",
    "unique_ids = [name + '_' if not name.endswith('_') else name for name in unique_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b25c5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['186714_1_93_R_', '457036_1_105_R_', '290336_3_114_R_', '295106_3_120_R_', '385151_3_154_L_', '157925_3_144_R_', '183417_3_144_R_', '157925_0_126_R_', '139486_2_99_R_', '157925_1_141_R_', '113994_3_108_L_', '186714_3_96_L_', '385151_0_126_R_', '283935_2_126_R_', '290336_0_120_L_', '295106_2_120_L_', '187456_2_120_L_', '385151_1_140_R_', '113994_2_99_L_', '183417_1_144_R_', '186714_1_93_L_', '290336_1_114_L_', '139486_3_111_R_', '290336_2_114_L_', '290336_3_114_L_', '380166_1_120_R_', '380166_3_129_R_', '385151_2_147_L_', '139486_1_99_R_', '457036_3_111_L_', '380166_2_138_R_', '385151_3_154_R_', '295106_0_108_R_', '295106_1_108_R_', '457036_2_105_R_', '380166_4_144_R_', '457036_0_105_L_', '139486_0_126_R_', '383193_6_147_L_', '290336_2_114_R_', '383193_3_138_R_', '186714_0_78_R_', '290336_0_120_R_', '295106_2_120_R_', '183417_0_129_R_', '186714_2_96_L_', '383193_4_117_R_', '385151_1_140_L_', '457036_0_105_R_', '457036_3_111_R_', '283935_3_114_R_', '187456_1_120_L_', '157925_2_144_R_', '283935_0_135_R_', '295106_1_108_L_', '295106_0_108_L_', '385151_0_126_L_', '385151_2_147_R_', '183417_2_144_R_', '186714_3_96_R_', '383193_3_138_L_', '383193_4_117_L_', '383193_5_129_R_', '113994_1_99_L_', '186714_0_78_L_', '186714_2_96_R_', '457036_1_105_L_', '295106_3_120_L_', '283935_1_135_R_', '113994_0_87_L_', '383193_5_129_L_', '290336_1_114_R_', '457036_2_105_L_', '383193_6_147_R_', '187456_0_87_L_', '187456_3_120_L_']\n"
     ]
    }
   ],
   "source": [
    "print(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055505a",
   "metadata": {},
   "source": [
    "# Stack Images, ground truth and predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f538ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(unique_ids)):\n",
    "    pt_info = unique_ids[i]\n",
    "    pt_num, yr_num, num_slices = re.findall(r'\\d+', pt_info)\n",
    "    tensor = np.zeros((128,128,int(num_slices)))\n",
    "    for x in range(int(num_slices)):\n",
    "        img_name = unique_ids[i]+str(x)+'_C.npy'\n",
    "        image = np.load(filepath_data + '\\\\' + img_name)\n",
    "        img_slice = image\n",
    "        tensor[:,:,x] = img_slice\n",
    "        x = x+1\n",
    "    new_fname = unique_ids[i]+'C.npy'\n",
    "    np.save(os.path.join(filepath_tensors, new_fname), tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fe9d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(unique_ids)):\n",
    "    pt_info = unique_ids[i]\n",
    "    pt_num, yr_num, num_slices = re.findall(r'\\d+', pt_info)\n",
    "    tensor = np.zeros((128,128,int(num_slices)))\n",
    "    for x in range(int(num_slices)):\n",
    "        img_name = unique_ids[i]+str(x)+'_M.npy'\n",
    "        image = np.load(filepath_data + '\\\\' + img_name)\n",
    "        img_slice = image\n",
    "        tensor[:,:,x] = img_slice\n",
    "        x = x+1\n",
    "    new_fname = unique_ids[i]+'M.npy'\n",
    "    np.save(os.path.join(filepath_tensors, new_fname), tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5628fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unique_ids)):\n",
    "    pt_info = unique_ids[i]\n",
    "    pt_num, yr_num, num_slices = re.findall(r'\\d+', pt_info)\n",
    "    tensor = np.zeros((128,128,int(num_slices)))\n",
    "    for x in range(int(num_slices)):\n",
    "        img_name = unique_ids[i]+str(x)+ '_' + model_name +'_P.npy'\n",
    "        image = np.load(filepath_predictions + '\\\\' + img_name)\n",
    "        img_slice = image[:,:,1]\n",
    "        tensor[:,:,x] = img_slice\n",
    "        x = x+1\n",
    "    new_fname = unique_ids[i]+ model_name +'_Prediction.npy'\n",
    "    np.save(os.path.join(filepath_tensors, new_fname), tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19659c4",
   "metadata": {},
   "source": [
    "Gather prediction tensors and calculate stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4bca7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['113994_0_87_L_test_Prediction.npy' '113994_1_99_L_test_Prediction.npy'\n",
      " '113994_2_99_L_test_Prediction.npy' '113994_3_108_L_test_Prediction.npy'\n",
      " '139486_0_126_R_test_Prediction.npy' '139486_1_99_R_test_Prediction.npy'\n",
      " '139486_2_99_R_test_Prediction.npy' '139486_3_111_R_test_Prediction.npy'\n",
      " '157925_0_126_R_test_Prediction.npy' '157925_1_141_R_test_Prediction.npy'\n",
      " '157925_2_144_R_test_Prediction.npy' '157925_3_144_R_test_Prediction.npy'\n",
      " '183417_0_129_R_test_Prediction.npy' '183417_1_144_R_test_Prediction.npy'\n",
      " '183417_2_144_R_test_Prediction.npy' '183417_3_144_R_test_Prediction.npy'\n",
      " '186714_0_78_L_test_Prediction.npy' '186714_0_78_R_test_Prediction.npy'\n",
      " '186714_1_93_L_test_Prediction.npy' '186714_1_93_R_test_Prediction.npy'\n",
      " '186714_2_96_L_test_Prediction.npy' '186714_2_96_R_test_Prediction.npy'\n",
      " '186714_3_96_L_test_Prediction.npy' '186714_3_96_R_test_Prediction.npy'\n",
      " '187456_0_87_L_test_Prediction.npy' '187456_1_120_L_test_Prediction.npy'\n",
      " '187456_2_120_L_test_Prediction.npy' '187456_3_120_L_test_Prediction.npy'\n",
      " '283935_0_135_R_test_Prediction.npy' '283935_1_135_R_test_Prediction.npy'\n",
      " '283935_2_126_R_test_Prediction.npy' '283935_3_114_R_test_Prediction.npy'\n",
      " '290336_0_120_L_test_Prediction.npy' '290336_0_120_R_test_Prediction.npy'\n",
      " '290336_1_114_L_test_Prediction.npy' '290336_1_114_R_test_Prediction.npy'\n",
      " '290336_2_114_L_test_Prediction.npy' '290336_2_114_R_test_Prediction.npy'\n",
      " '290336_3_114_L_test_Prediction.npy' '290336_3_114_R_test_Prediction.npy'\n",
      " '295106_0_108_L_test_Prediction.npy' '295106_0_108_R_test_Prediction.npy'\n",
      " '295106_1_108_L_test_Prediction.npy' '295106_1_108_R_test_Prediction.npy'\n",
      " '295106_2_120_L_test_Prediction.npy' '295106_2_120_R_test_Prediction.npy'\n",
      " '295106_3_120_L_test_Prediction.npy' '295106_3_120_R_test_Prediction.npy'\n",
      " '380166_1_120_R_test_Prediction.npy' '380166_2_138_R_test_Prediction.npy'\n",
      " '380166_3_129_R_test_Prediction.npy' '380166_4_144_R_test_Prediction.npy'\n",
      " '383193_3_138_L_test_Prediction.npy' '383193_3_138_R_test_Prediction.npy'\n",
      " '383193_4_117_L_test_Prediction.npy' '383193_4_117_R_test_Prediction.npy'\n",
      " '383193_5_129_L_test_Prediction.npy' '383193_5_129_R_test_Prediction.npy'\n",
      " '383193_6_147_L_test_Prediction.npy' '383193_6_147_R_test_Prediction.npy'\n",
      " '385151_0_126_L_test_Prediction.npy' '385151_0_126_R_test_Prediction.npy'\n",
      " '385151_1_140_L_test_Prediction.npy' '385151_1_140_R_test_Prediction.npy'\n",
      " '385151_2_147_L_test_Prediction.npy' '385151_2_147_R_test_Prediction.npy'\n",
      " '385151_3_154_L_test_Prediction.npy' '385151_3_154_R_test_Prediction.npy'\n",
      " '457036_0_105_L_test_Prediction.npy' '457036_0_105_R_test_Prediction.npy'\n",
      " '457036_1_105_L_test_Prediction.npy' '457036_1_105_R_test_Prediction.npy'\n",
      " '457036_2_105_L_test_Prediction.npy' '457036_2_105_R_test_Prediction.npy'\n",
      " '457036_3_111_L_test_Prediction.npy' '457036_3_111_R_test_Prediction.npy']\n",
      "['113994_0_87_L_C.npy' '113994_1_99_L_C.npy' '113994_2_99_L_C.npy'\n",
      " '113994_3_108_L_C.npy' '139486_0_126_R_C.npy' '139486_1_99_R_C.npy'\n",
      " '139486_2_99_R_C.npy' '139486_3_111_R_C.npy' '157925_0_126_R_C.npy'\n",
      " '157925_1_141_R_C.npy' '157925_2_144_R_C.npy' '157925_3_144_R_C.npy'\n",
      " '183417_0_129_R_C.npy' '183417_1_144_R_C.npy' '183417_2_144_R_C.npy'\n",
      " '183417_3_144_R_C.npy' '186714_0_78_L_C.npy' '186714_0_78_R_C.npy'\n",
      " '186714_1_93_L_C.npy' '186714_1_93_R_C.npy' '186714_2_96_L_C.npy'\n",
      " '186714_2_96_R_C.npy' '186714_3_96_L_C.npy' '186714_3_96_R_C.npy'\n",
      " '187456_0_87_L_C.npy' '187456_1_120_L_C.npy' '187456_2_120_L_C.npy'\n",
      " '187456_3_120_L_C.npy' '283935_0_135_R_C.npy' '283935_1_135_R_C.npy'\n",
      " '283935_2_126_R_C.npy' '283935_3_114_R_C.npy' '290336_0_120_L_C.npy'\n",
      " '290336_0_120_R_C.npy' '290336_1_114_L_C.npy' '290336_1_114_R_C.npy'\n",
      " '290336_2_114_L_C.npy' '290336_2_114_R_C.npy' '290336_3_114_L_C.npy'\n",
      " '290336_3_114_R_C.npy' '295106_0_108_L_C.npy' '295106_0_108_R_C.npy'\n",
      " '295106_1_108_L_C.npy' '295106_1_108_R_C.npy' '295106_2_120_L_C.npy'\n",
      " '295106_2_120_R_C.npy' '295106_3_120_L_C.npy' '295106_3_120_R_C.npy'\n",
      " '380166_1_120_R_C.npy' '380166_2_138_R_C.npy' '380166_3_129_R_C.npy'\n",
      " '380166_4_144_R_C.npy' '383193_3_138_L_C.npy' '383193_3_138_R_C.npy'\n",
      " '383193_4_117_L_C.npy' '383193_4_117_R_C.npy' '383193_5_129_L_C.npy'\n",
      " '383193_5_129_R_C.npy' '383193_6_147_L_C.npy' '383193_6_147_R_C.npy'\n",
      " '385151_0_126_L_C.npy' '385151_0_126_R_C.npy' '385151_1_140_L_C.npy'\n",
      " '385151_1_140_R_C.npy' '385151_2_147_L_C.npy' '385151_2_147_R_C.npy'\n",
      " '385151_3_154_L_C.npy' '385151_3_154_R_C.npy' '457036_0_105_L_C.npy'\n",
      " '457036_0_105_R_C.npy' '457036_1_105_L_C.npy' '457036_1_105_R_C.npy'\n",
      " '457036_2_105_L_C.npy' '457036_2_105_R_C.npy' '457036_3_111_L_C.npy'\n",
      " '457036_3_111_R_C.npy']\n"
     ]
    }
   ],
   "source": [
    "filepath_tensors = filepath_tensors\n",
    "pred_list = gather_set(filepath_tensors, '_Prediction')\n",
    "true_list = gather_set(filepath_tensors, '_C.')\n",
    "print(pred_list)\n",
    "print(true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39843b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Prediction.npy\n",
      "113994_0_87_L_tesC.npy\n"
     ]
    }
   ],
   "source": [
    "name =pred_list[0]\n",
    "print(name[18:46])\n",
    "test = pred_list[0][:17]+'C.npy'\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fce80b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(pred_list)):\n",
    "    prediction = np.load(filepath_tensors + '\\\\'+ pred_list[i])\n",
    "    true = np.load(filepath_tensors + '\\\\'+true_list[i])\n",
    "    hd_dist = (HD(true, prediction)/100)\n",
    "    hd_dist1 = HD1(true, prediction)\n",
    "    #mean_error = mean_length_error(true, prediction)\n",
    "    jac=(jaccard_distance_loss(true, prediction)/100)\n",
    "    #dist = dist/10\n",
    "    dice_calc = dice_coef(true,prediction)\n",
    "    #sen = sensitivity(true, prediction)\n",
    "    #spec = specificity(true, prediction)\n",
    "    #rocs = roc(true, prediction)\n",
    "    #accuracy_score(true, prediction, normalize=True, sample_weight=None)\n",
    "    #true = true>0.5\n",
    "    \n",
    "    #prediction = prediction > 0.5   \n",
    "    \n",
    " \n",
    "    #auc = metrics.roc_auc_score(true, prediction)\n",
    "    iou_dist = IOU(true,prediction)\n",
    "    #jac1 = jaccard_score(true, prediction,average='binary')\n",
    "    \n",
    "    if dice_calc>0.68:\n",
    "        #model = pred_list[i][18:46]\n",
    "        patient = pred_list[i][:17]\n",
    "        new_calc = [dice_calc.numpy(), hd_dist, hd_dist1.numpy, jac.numpy(), iou_dist]\n",
    "        #new_calc = [dice_calc.numpy()]\n",
    "        results.append(new_calc)\n",
    "    #else:\n",
    "     #   continue\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6e7107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Dice Coefficient: 0.9276232230374234\n",
      "Minimum HD Distance: 2.7455182373482154\n",
      "Minimum HD1 Distance: 0.0340796368255012\n",
      "Minimum Jaccard Distance: 0.8652003653892223\n",
      "Minimum IOU Distance: 0.1310603050435856\n",
      "Dice Coefficient Average: 0.874053236635457\n"
     ]
    }
   ],
   "source": [
    "min_values = []\n",
    "for col in zip(*results):\n",
    "    col_values = [float(val()) if callable(val) else float(val) for val in col]\n",
    "    col_min = max(col_values)\n",
    "    min_values.append(col_min)\n",
    "\n",
    "# patient_min = min_values[0]  # Minimum value of patient values\n",
    "dice_calc_min = min_values[0]  # Minimum value of dice_calc values\n",
    "hd_dist_min = min_values[1]  # Minimum value of hd_dist values\n",
    "hd_dist1_min = min_values[2]  # Minimum value of hd_dist1 values\n",
    "jac_min = min_values[3]  # Minimum value of jac values\n",
    "iou_dist_min = min_values[4]  # Minimum value of iou_dist values\n",
    "print(\"Minimum Dice Coefficient:\", dice_calc_min)\n",
    "print(\"Minimum HD Distance:\", hd_dist_min)\n",
    "print(\"Minimum HD1 Distance:\", hd_dist1_min)\n",
    "print(\"Minimum Jaccard Distance:\", jac_min)\n",
    "print(\"Minimum IOU Distance:\", iou_dist_min)\n",
    "averages = []\n",
    "for col in zip(*results):\n",
    "    col_values = [float(val()) if callable(val) else float(val) for val in col]\n",
    "    col_avg = sum(col_values) / len(col_values)\n",
    "    averages.append(col_avg)\n",
    "dice_calc_avg = averages[0]\n",
    "print(\"Dice Coefficient Average:\", dice_calc_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "652c102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient Average: 0.874053236635457\n",
      "HD Distance Average: 1.485669875657145\n",
      "HD1 Distance Average: 0.012062798911875084\n",
      "Jaccard Distance Average: 0.7783707200849137\n",
      "IOU Distance Average: 0.051112680959561424\n"
     ]
    }
   ],
   "source": [
    "averages = []\n",
    "for col in zip(*results):\n",
    "    col_values = [float(val()) if callable(val) else float(val) for val in col]\n",
    "    col_avg = sum(col_values) / len(col_values)\n",
    "    averages.append(col_avg)\n",
    "\n",
    "#patient_avg = averages[0]  # Average of patient values\n",
    "dice_calc_avg = averages[0]  # Average of dice_calc values\n",
    "hd_dist_avg = averages[1]  # Average of hd_dist values\n",
    "hd_dist1_avg = averages[2]  # Average of hd_dist1 values\n",
    "jac_avg = averages[3]  # Average of jac values\n",
    "iou_dist_avg = averages[4]  # Average of iou_dist values\n",
    "print(\"Dice Coefficient Average:\", dice_calc_avg)\n",
    "print(\"HD Distance Average:\", hd_dist_avg)\n",
    "print(\"HD1 Distance Average:\", hd_dist1_avg)\n",
    "print(\"Jaccard Distance Average:\", jac_avg)\n",
    "print(\"IOU Distance Average:\", iou_dist_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a80146d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient Standard Deviation: 0.35125538079412033\n",
      "HD Distance Standard Deviation: 0.7026550634305502\n",
      "HD1 Distance Standard Deviation: 0.9578748845365637\n",
      "Jaccard Distance Standard Deviation: 0.4713160728261426\n",
      "IOU Distance Standard Deviation: 1.079626778408779\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Calculate standard deviation for each parameter\n",
    "dice_calc_sd = math.sqrt(sum((float(val()) if callable(val) else float(val) - dice_calc_avg) ** 2 for val in results[0]) / len(results[0]))\n",
    "hd_dist_sd = math.sqrt(sum((float(val()) if callable(val) else float(val) - hd_dist_avg) ** 2 for val in results[1]) / len(results[1]))\n",
    "hd_dist1_sd = math.sqrt(sum((float(val()) if callable(val) else float(val) - hd_dist1_avg) ** 2 for val in results[2]) / len(results[2]))\n",
    "jac_sd = math.sqrt(sum((float(val()) if callable(val) else float(val) - jac_avg) ** 2 for val in results[3]) / len(results[3]))\n",
    "iou_dist_sd = math.sqrt(sum((float(val()) if callable(val) else float(val) - iou_dist_avg) ** 2 for val in results[4]) / len(results[4]))\n",
    "\n",
    "# Print standard deviation values\n",
    "print(\"Dice Coefficient Standard Deviation:\", dice_calc_sd)\n",
    "print(\"HD Distance Standard Deviation:\", hd_dist_sd)\n",
    "print(\"HD1 Distance Standard Deviation:\", hd_dist1_sd)\n",
    "print(\"Jaccard Distance Standard Deviation:\", jac_sd)\n",
    "print(\"IOU Distance Standard Deviation:\", iou_dist_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba0e9e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['113994_0_87_L_tes', 0.8835635305066377], ['113994_1_99_L_tes', 0.8914922152092589], ['113994_2_99_L_tes', 0.8564934053918366], ['113994_3_108_L_te', 0.8934202600974314], ['139486_0_126_R_te', 0.9222143150392268], ['139486_1_99_R_tes', 0.9082955230969956], ['139486_2_99_R_tes', 0.9286691555879607], ['139486_3_111_R_te', 0.9129185161860741], ['157925_0_126_R_te', 0.8985464396452444], ['157925_1_141_R_te', 0.8952782078004687], ['157925_2_144_R_te', 0.883488930106251], ['157925_3_144_R_te', 0.9049351171785605], ['183417_0_129_R_te', 0.8453222321389027], ['183417_1_144_R_te', 0.8333218547638429], ['183417_2_144_R_te', 0.8695757761438256], ['183417_3_144_R_te', 0.8387048906656192], ['186714_0_78_L_tes', 0.889412605976103], ['186714_0_78_R_tes', 0.8963161398192137], ['186714_1_93_L_tes', 0.8939967145485421], ['186714_1_93_R_tes', 0.8807512055201604], ['186714_2_96_L_tes', 0.8964511230274046], ['186714_2_96_R_tes', 0.8918503689453008], ['186714_3_96_L_tes', 0.9014284297581412], ['186714_3_96_R_tes', 0.8914066553884591], ['187456_0_87_L_tes', 0.8376125386741038], ['187456_1_120_L_te', 0.7834111488702303], ['187456_2_120_L_te', 0.8719975252670579], ['187456_3_120_L_te', 0.8396779235741831], ['283935_0_135_R_te', 0.782456300694144], ['283935_1_135_R_te', 0.9224293062014783], ['283935_2_126_R_te', 0.7170911575193176], ['283935_3_114_R_te', 0.8617708426035608], ['290336_0_120_L_te', 0.7646300321714062], ['290336_0_120_R_te', 0.7188860428715725], ['290336_1_114_L_te', 0.8997311990897863], ['290336_1_114_R_te', 0.8896434314483053], ['290336_2_114_L_te', 0.9073077231661594], ['290336_2_114_R_te', 0.9094306681802574], ['290336_3_114_L_te', 0.8893333276715658], ['290336_3_114_R_te', 0.9112972888842823], ['295106_0_108_L_te', 0.8084483629102212], ['295106_0_108_R_te', 0.8695431507571169], ['295106_1_108_L_te', 0.8677910157975467], ['295106_1_108_R_te', 0.8966799484708411], ['295106_2_120_L_te', 0.8851080247278349], ['295106_2_120_R_te', 0.9155883593320022], ['295106_3_120_L_te', 0.8768011106839891], ['295106_3_120_R_te', 0.8727277278083178], ['380166_1_120_R_te', 0.8857415407858813], ['380166_2_138_R_te', 0.9002967839231022], ['380166_3_129_R_te', 0.8551380743002045], ['380166_4_144_R_te', 0.8730019063765139], ['383193_3_138_L_te', 0.9002087444986941], ['383193_3_138_R_te', 0.8578343993069848], ['383193_4_117_L_te', 0.8227963960870961], ['383193_4_117_R_te', 0.813126070945089], ['383193_5_129_L_te', 0.8678464186969796], ['383193_5_129_R_te', 0.8312025603960245], ['383193_6_147_L_te', 0.879085154072917], ['383193_6_147_R_te', 0.8078333488152196], ['385151_0_126_L_te', 0.817700647750293], ['385151_0_126_R_te', 0.9022738146969455], ['385151_1_140_L_te', 0.7410221146157093], ['385151_1_140_R_te', 0.8763035684454551], ['385151_2_147_L_te', 0.8559966797123962], ['385151_2_147_R_te', 0.8867411016275605], ['385151_3_154_L_te', 0.8530546273024133], ['385151_3_154_R_te', 0.885968506140881], ['457036_0_105_L_te', 0.9058489198449781], ['457036_0_105_R_te', 0.8995017600377094], ['457036_1_105_L_te', 0.8513308770787534], ['457036_1_105_R_te', 0.9038080535029303], ['457036_2_105_L_te', 0.8764424354180439], ['457036_2_105_R_te', 0.8988347465396909], ['457036_3_111_L_te', 0.8917080484556974], ['457036_3_111_R_te', 0.8727960802797787]]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e273351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.columns =[ 'Dice', 'HD', 'HD1', 'IOU', 'IOU1' ]\n",
    "#df.columns =[ 'Dice']\n",
    "filepath = r\"D:\\Results_CK\\sUNet++\\Cyst\\performance.xlsx\"\n",
    "df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68843c47",
   "metadata": {},
   "source": [
    "# Convert predictions to nii for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5346148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_images(data_path):\n",
    "    images = []\n",
    "    path = data_path + '\\\\'\n",
    "    for f in os.listdir(data_path):\n",
    "      if '_test' in f:\n",
    "        images.append(f)\n",
    "        \n",
    "      else:\n",
    "        continue\n",
    "    images = np.array(images)\n",
    "    #segmentations = np.array(segmentations)\n",
    "\n",
    "    indices = np.array(range(len(images))) # we will use this in the next step.\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef9a47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "filepath_tensors = r'D:\\t'\n",
    "images = gather_images(filepath_tensors)\n",
    "print(len(images))\n",
    "path = r'D:\\Results_CK\\sUNet++\\Cyst\\nii'\n",
    "for i in range(len(images)):\n",
    "    image = np.load(os.path.join(filepath_tensors, images[i]))\n",
    "    affine = np.eye(4)\n",
    "    nifti_file = nib.Nifti1Image(image, affine)\n",
    "    filename = images[i][:-3]+'nii'\n",
    "    nib.save(nifti_file, os.path.join(path, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
